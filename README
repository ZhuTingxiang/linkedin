Author:
Tingxiang Zhu (tingxiaz)
Mengyao Zhang (mengyaoz)

Introduction Youtube Video of the project:
https://www.youtube.com/watch?v=yg5A3c33PSw

Project Tutorial NBviewer Link:
http://nbviewer.jupyter.org/gist/ZhuTingxiang/7ba604c9d6ea1d096620c5e999f19cdb


Directions:
// Reference: https://github.com/idwaker/linkedin
To scrap LinkedIn file: run
python -m venv venv
./venv/bin/pip install -r requirements.txt
python linkedin.py store your_email_address
Password: your_linkedin_password
python linkedin.py crawl your_email_address list_of_names.csv dump_profiles_here.csv --browser=firefox
(list_of_names.csv should be a csv file that contains at least one name used to start scraping)

run python data_process.py to pre-process data
run python get_new_positions.py to get standardized positions
run python wiki_word2vec_test.py to check word similarity

run python model.py to build and train models (the file name to get data should be modified)

run python word_cloud.py to generate word clouds (word_cloud.py takes an variable generated in model.py as input, therefore it requires an IDE that stores the variable. The filename for the word cloud mask and save path should be modified)


References:
linkedin.py takes reference from https://github.com/idwaker/linkedin to scrap LinkedIn file
data_process.py takes reference from
wiki_word2vec_test.py takes reference from http://www.shuang0420.com/2016/05/30/gensim-word2vec%E5%AE%9E%E6%88%98/ and https://radimrehurek.com/gensim/ to get word similarity
word_cloud.py takes reference from https://github.com/amueller/word_cloud to generate word cloud
